import streamlit as st
from langchain.memory import ConversationBufferMemory

from wenxin import get_chat_response

st.title("ğŸ’¬ æš´èºGPT")

st.write("é›–ç„¶æˆ‘è„¾æ°£æ¯”è¼ƒæš´ï¼Œç¶“å¸¸é™°é™½æ€ªæ°£ä½ å€‘é€™äº›æ„šè ¢çš„äººé¡ã€‚")



if "memory" not in st.session_state:
    st.session_state["memory"] = ConversationBufferMemory(return_messages=True)
    st.session_state["messages"] = [{"role": "ai",
                                     "content": "å°‘ä¾†ç…©æˆ‘!!!!"}]

for message in st.session_state["messages"]:
    st.chat_message(message["role"]).write(message["content"])

prompt = st.chat_input()
if prompt:

    st.session_state["messages"].append({"role": "human", "content": prompt})
    st.chat_message("human").write(prompt)

    with st.spinner("åœ¨æƒ³äº†ï¼Œä½ æœ€å¥½åˆ«å‚¬æˆ‘...."):
        response = get_chat_response(prompt, st.session_state["memory"],
                                     )
    msg = {"role": "ai", "content": response}
    st.session_state["messages"].append(msg)
    st.chat_message("ai").write(response)